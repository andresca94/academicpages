---
layout: archive
title: "A Case Study with Barbara Feldon from Get Smart Using ComfyUI"
permalink: /workflows/
author_profile: true
---
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Case Study: Barbara Feldon with ComfyUI</title>
  <style>
    section {
      margin-bottom: 3rem;
    }
    h1, h2, h3 {
      color: #333;
    }
    p, li {
      font-size: 1rem;
      line-height: 1.6;
    }
    /* Image Gallery Styling */
    .image-gallery {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      justify-content: center;
      margin-bottom: 20px;
    }
    .image-gallery img {
      width: 300px;
      height: 300px;
      border-radius: 8px;
      object-fit: cover;
    }
  </style>
</head>
<body>

  <!--
    TITLE & INTRO
  -->
  <section>
    <p>
      In this creative project, we explore various capabilities of <strong>ComfyUI</strong> through the iconic actress <strong>Barbara Feldon</strong>, best known for her role as Agent 99 in the classic 1965–1970 TV series <em>Get Smart</em>. We utilize advanced tools such as FLUX, Hunyuan3D, and AnimateDiff to process, enhance, and animate Barbara’s visuals. This case study demonstrates a complete AI-assisted creative workflow from image restoration to video generation.
    </p>
    <!--
      Source Reference: ComfyUI initial release in Jan 2023 by comfyanonymous
      https://github.com/comfyanonymous/ComfyUI
    -->
  </section>

  <hr>

  <!--
    PART ONE: IMAGE PROCESSING
  -->
  <section>
    <h2>Part One: Image Processing</h2>

    <h3>Original Photographs of Barbara Feldon</h3>
    <p>
      Here we display original photos of Barbara Feldon, which serve as the basis for subsequent transformations and enhancements. These images were selected for their clarity and representative facial angles, ideal for training LoRAs and exploring editing workflows.
    </p>

    <div class="image-gallery">
      <!-- Example usage with Jekyll's relative_url filter; adjust paths as needed. -->
      <img src="{{ '/images/barbara_original_1.jpg' | relative_url }}" alt="Barbara Feldon Original 1" />
      <img src="{{ '/images/barbara_original_2.jpg' | relative_url }}" alt="Barbara Feldon Original 2" />
      <img src="{{ '/images/barbara_original_3.jpg' | relative_url }}" alt="Barbara Feldon Original 3" />
      <img src="{{ '/images/barbara_original_4.jpg' | relative_url }}" alt="Barbara Feldon Original 4" />
      <img src="{{ '/images/barbara_original_5.jpg' | relative_url }}" alt="Barbara Feldon Original 1" />
      <img src="{{ '/images/barbara_original_6.jpg' | relative_url }}" alt="Barbara Feldon Original 2" />
      <img src="{{ '/images/barbara_original_7.jpg' | relative_url }}" alt="Barbara Feldon Original 3" />
      <img src="{{ '/images/barbara_original_8.jpg' | relative_url }}" alt="Barbara Feldon Original 4" />
      <img src="{{ '/images/barbara_original_9.jpg' | relative_url }}" alt="Barbara Feldon Original 1" />
      <img src="{{ '/images/barbara_original_10.jpg' | relative_url }}" alt="Barbara Feldon Original 2" />
      <img src="{{ '/images/barbara_original_11.jpg' | relative_url }}" alt="Barbara Feldon Original 3" />
      <img src="{{ '/images/barbara_original_12.jpg' | relative_url }}" alt="Barbara Feldon Original 4" />
    </div>

    <h3>FLUX and Its Capabilities (2023)</h3>
    <p>
      <strong>FLUX</strong> is a powerful modular toolkit released in <em>mid-2023</em> by Black Forest Labs (BFL) for ComfyUI. It enables advanced inpainting, upscaling, animation, and LoRA training, built atop Stable Diffusion technology.
      <!-- 
        Reference: 
        - "Flux Tools" official release in 2023 by BFL, see flux-labs/flux-tools (GitHub).
        - Noted in the ComfyUI registry around the same period.
      -->
      It has revolutionized the AI art pipeline by streamlining creative workflows for both beginners and seasoned artists.
    </p>

    <!-- Numbered list for Part One -->
    <ul>
      <li>
        <strong>1.1: Inpainting and Outpainting with FLUX</strong><br>
        

        <strong>Flux Fill | Inpaint and Outpaint</strong><br>
        <em>Introduction:</em> Flux Fill uses advanced in/outpainting models to modify both real and AI-generated images. By providing text prompts and masks, it can add or remove elements, fix details, or expand the canvas.        
        <br><br>
        <strong>Example Workflow Highlights:</strong>
        <ul>
          <li>Inpainting: Replace or remove unwanted parts of the image.</li>
          <div class="image-gallery">
            <!-- Example usage with Jekyll's relative_url filter; adjust paths as needed. -->
            <img src="{{ '/images/in1.png' | relative_url }}" alt="Barbara Feldon Original 1" />
            <img src="{{ '/images/in2.png' | relative_url }}" alt="Barbara Feldon Original 2" />
            <img src="{{ '/images/in3.png' | relative_url }}" alt="Barbara Feldon Original 3" />
            <img src="{{ '/images/in4.png' | relative_url }}" alt="Barbara Feldon Original 4" />
          </div>
          <li>Outpainting: Expand the canvas for more background content.</li>
          <div class="image-gallery">
            <!-- Example usage with Jekyll's relative_url filter; adjust paths as needed. -->
            <img src="{{ '/images/out1.png' | relative_url }}" alt="Barbara Feldon Original 1" />
            <img src="{{ '/images/out2.png' | relative_url }}" alt="Barbara Feldon Original 2" />
            <img src="{{ '/images/out3.png' | relative_url }}" alt="Barbara Feldon Original 3" />
            <img src="{{ '/images/out4.png' | relative_url }}" alt="Barbara Feldon Original 4" />
          </div>
        </ul>
        <p>
          The Flux Fill models and nodes, along with their workflows, are fully developed by Blackforest Labs. I appreciate their innovative work, presented here for community benefit.
        </p>
        <p>
          <strong>How to Use:</strong><br>
          1. Provide an input image (for inpainting/outpainting).<br>
          2. Specify your text prompts and relevant mask(s).<br>
          3. Execute the workflow to generate the new image content.<br>
          4. Optional: Adjust sample steps or outpainting parameters to refine results.
        </p>
      </li>

      <li>
        <strong>1.2: FLUX Upscaler (2023)</strong><br>
        Enhances resolution and image quality. Useful for refining Barbara’s photos prior to training or transformations.
        The Flux Upscaler uses the Ultimate SD Upscaler node to preserve detail and clarity while boosting resolution (4k, 8k, up to 32k). Perfect for professional-grade enlargements or ensuring crisp details for further editing or LoRA training.
        <div class="image-gallery">
          <img src="{{ '/images/barbara_original_3.jpg' | relative_url }}" alt="Barbara Feldon Original 4" />
        <img src="{{ '/images/up.png' | relative_url }}" alt="Barbara Feldon Original 4" />
      </div>
        <br><br>
        <strong>How to Use:</strong>
        <ul>
          <li>Load the photo in the upscaler node.</li>
          <li>Set target resolution (e.g. 2x, 4x, or custom pixel size).</li>
          <li>Click to run; the upscaled result is saved for subsequent workflows.</li>
        </ul>
      </li>

      <li>
        <strong>1.3: FLUX LoRA Character Consistency Training</strong><br>
        Uses upscaled photos to train a LoRA for consistent facial identity. LoRA (proposed in 2021) is widely adopted across diffusion models for stable or stylized character replication. This ensures Barbara’s features remain accurate across varied poses and styles.To generate ‘boring/amateur photo’ style images we add the camera file extension to the prompt, like this:

        DSC_0043.JPG
        DSC09876.RW2
        IMG_45678.CR2
        Selfie_IMG_1998.HEIC
        
        This will reference imagery more closely associated with RAW and realistic photos.
        
        Works best with short prompts, larger dimension to 1024x1024, High CFG: 7-12 and Steps: 25-30.
      </li>
      <div class="image-gallery">
        <!-- Example usage with Jekyll's relative_url filter; adjust paths as needed. -->
        <img src="{{ '/images/out1.png' | relative_url }}" alt="Barbara Feldon Original 1" />
        <img src="{{ '/images/out2.png' | relative_url }}" alt="Barbara Feldon Original 2" />
        <img src="{{ '/images/out3.png' | relative_url }}" alt="Barbara Feldon Original 3" />
        <img src="{{ '/images/out4.png' | relative_url }}" alt="Barbara Feldon Original 4" />
      </div>

      <li>
        <strong>1.4: 3D with Hunyuan3D-2 (2024)</strong><br>
        Converts images to detailed 3D meshes using diffusion-based geometry generation. This technology expands creative possibilities by producing a 3D model from a single photo.
        <br><br>
        A two-stage 3D generation system from Tencent, featuring a shape generation model (Hunyuan3D-DiT) and a texture synthesis model (Hunyuan3D-Paint). 
        <p>
          <strong>Key Steps:</strong><br>
          1. Prepare the input photo.<br>
          2. Hunyuan3D-2 extracts geometry and produces a 3D mesh.<br>
          3. Texture synthesis finalizes a high-resolution texture for the 3D asset.
        </p>
      </li>

      <li>
        <strong>1.5: FLUX Depth Canny + ToonCrafter (2023)</strong><br>
        Applies depth and edge data for cartoon-style interpolation. <em>ToonCrafter</em> (by CUHK & Tencent AI Lab) can generate cartoon transitions or partial animations from existing images.
        <p>
        Combine depth and edge detection to maintain structure or perspective. This is useful for stylized transformations, ensuring correct outlines and basic 3D cues.
        </p>
      </li>

      <li>
        <strong>1.6: FLUX Redux (2023)</strong><br>
        Official FLUX restyling toolkit for generating style variations while preserving identity. It can restyle entire images using LoRA-based transformations for subtle or dramatic changes.
      </li>

      <li>
        <strong>1.7: CatVTON (2023)</strong><br>
        High-fidelity virtual try-on system merging diffusion with NeRF-like 3D reasoning for realistic garment overlays. Developed by Zheng Chong et al. and presented at ICLR 2025.
      </li>
    </ul>
  </section>

  <hr>

  <!--
    PART TWO: VIDEO GENERATION & ANIMATION
  -->
  <section>
    <h2>Part Two: Video Generation & Animation</h2>
    <p>
      In this phase, we apply generative and animation tools to bring Barbara Feldon to life through video sequences, dance animations, and stylized performances. These tools build on the LoRA and processed images above for consistent identity and artistic fidelity.
    </p>

    <!-- Numbered list for Part Two -->
    <ul>
      <li>
        <strong>2.1: ReActor (2023)</strong> — Face Swap Module<br>
        Allows face swapping in videos using real or generated reference portraits. Originally a Stable Diffusion WebUI extension, later integrated into ComfyUI. 
        <p>
        Powered by advanced models like inswapper_128 and retinaface_resnet50. Face boosting and RealESRGAN upscaling can be used to refine final results. Perfect for character animations or content requiring face replacements.
        </p>
      </li>

      <li>
        <strong>2.2: Sonic (2023)</strong> — Lip-Sync Portrait Animation<br>
        Generates accurate lip movements from audio plus a portrait still. Developed by Tencent & Zhejiang University, focusing on global audio priors for expression realism.
      </li>

      <li>
        <strong>2.3: LivePortrait (2023)</strong> — Vid2Vid Module<br>
        Uses reference video to animate facial expressions and head movements. Introduced by Kuaishou AI in mid-2024, referenced as 2023 for synergy with ComfyUI workflows.
      </li>

      <li>
        <strong>2.4: Hunyuan IP2V (2024)</strong> — Image-to-Video Engine<br>
        Converts static images into dynamic scenes guided by prompts and style references. Part of Tencent’s Hunyuan ecosystem, supporting up to 720p at 24fps for short video sequences.
      </li>

      <li>
        <strong>2.5: IC-Light Video Relighting + AnimateDiff (2023)</strong><br>
        Combines advanced lighting correction (IC-Light) and frame-by-frame animation generation (AnimateDiff) to produce consistent cinematic motion with well-adjusted illumination.
      </li>

      <li>
        <strong>2.6: Hunyuan LoRA (2024)</strong><br>
        Applies custom or pre-trained LoRA styles to frames for comic-book or illustrative effects. Developed by Tencent for advanced 2D or 3D stylization.
      </li>

      <li>
        <strong>2.7: CogvideoX Fun (2023)</strong> — Video-to-Video Cinematic Edit<br>
        A text-to-video system from Tsinghua & Zhipu AI, enabling stylized transformations from one video to another via deep frame matching.
      </li>

      <li>
        <strong>2.8: Epic CineFX (2023)</strong><br>
        Enhances videos with cinematic color grading, transitions, and filters. Often used alongside ControlNet and upscaling for polished final results.
      </li>

      <li>
        <strong>2.9: Hunyuan Video (2024)</strong><br>
        Tencent’s advanced Video-to-Video solution guided by prompts and LoRA styles, supporting higher resolutions and dynamic 3D backgrounds. Successor to IP2V.
      </li>
    </ul>
  </section>

</body>
</html>
